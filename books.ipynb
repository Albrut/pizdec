{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0b048e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтение файлов...\n",
      "Токенизация...\n",
      "Обработано предложений: 1064\n",
      "Версия SimAlign: Неизвестно\n",
      "Проверка методов SimAlign...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 02:09:33,218 - simalign.simalign - INFO - Initialized the EmbeddingLoader with model: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметр matching_methods: mai\n",
      "Тестовый запуск...\n",
      "Доступные методы в результате: ['mwmf', 'inter', 'itermax']\n",
      "Запуск основного выравнивания...\n",
      "Инициализация SimAlign...\n",
      "Ошибка при создании aligner с методом 'mwmf': 'w'\n",
      "Попытка инициализации без параметра matching_methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 02:09:33,987 - simalign.simalign - INFO - Initialized the EmbeddingLoader with model: distilbert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimAlign инициализирован успешно!\n",
      "Начинаем обработку 10 предложений...\n",
      "Обработка пары 1...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "Обработка пары 2...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "Обработка пары 3...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "Обработка пары 4...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "Обработка пары 5...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "Обработка пары 6...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "Обработка пары 7...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "Обработка пары 8...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "Обработка пары 9...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "Обработка пары 10...\n",
      "Ключи в результате: ['mwmf', 'inter', 'itermax']\n",
      "Используем метод: mwmf\n",
      "SimAlign нашёл выравнивание в 10/1064 предложениях\n",
      "\n",
      "Примеры выравниваний (первые 5):\n",
      "\n",
      "#Пара 1:\n",
      "RU: Ночь первая\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Была чудная ночь, такая ночь, которая разве только и может быть тогда, когда мы молоды, любезный читатель.\n",
      "EN: FIRST NIGHT\n",
      "\n",
      "It was a wonderful night, such a night as is only possible when we are\n",
      "young, dear reader.\n",
      "Alignment: [(0, 0), (0, 5), (1, 2), (2, 1), (3, 5), (3, 18), (4, 3), (4, 6), (5, 7), (5, 8), (6, 6), (6, 9), (7, 4), (10, 10), (11, 12), (12, 0), (13, 11), (13, 13), (14, 14), (15, 15), (16, 0), (16, 5), (16, 16), (16, 17), (17, 1), (17, 17), (17, 18), (18, 19)]\n",
      "\n",
      "#Пара 2:\n",
      "RU: Небо было такое звездное, такое светлое небо, что, взглянув на него, невольно нужно было спросить себя: неужели же могут жить под таким небом разные сердитые и капризные люди?\n",
      "EN: The sky was so starry, so bright that, looking at\n",
      "it, one could not help asking oneself whether ill-humoured and\n",
      "capricious people could live under such a sky.\n",
      "Alignment: [(0, 12), (0, 13), (1, 2), (2, 3), (3, 4), (3, 6), (4, 5), (5, 4), (5, 20), (5, 26), (6, 0), (6, 1), (7, 7), (8, 14), (9, 9), (10, 10), (14, 15), (14, 16), (14, 18), (15, 8), (15, 27), (16, 16), (16, 18), (16, 20), (17, 11), (18, 22), (19, 23), (20, 24), (21, 25), (22, 18), (22, 27), (25, 19), (26, 18), (26, 20), (27, 17), (27, 21)]\n",
      "\n",
      "#Пара 3:\n",
      "RU: Это тоже молодой вопрос, любезный читатель, очень молодой, но пошли его вам господь чаще на душу!..\n",
      "EN: That is a youthful\n",
      "question too, dear reader, very youthful, but may the Lord put it more\n",
      "frequently into your heart!...\n",
      "Alignment: [(0, 0), (1, 1), (2, 2), (3, 4), (3, 5), (4, 5), (4, 12), (4, 17), (4, 19), (5, 3), (5, 7), (5, 9), (6, 8), (7, 9), (8, 10), (9, 11), (9, 13), (10, 15), (11, 6), (12, 14), (12, 18), (12, 20), (13, 16), (14, 20), (15, 7), (15, 20)]\n",
      "\n",
      "#Пара 4:\n",
      "RU: Говоря о капризных и разных сердитых господах, я не мог не припомнить и своего благонравного поведения во весь этот день.\n",
      "EN: Speaking of capricious and ill-humoured\n",
      "people, I cannot help recalling my moral condition all that day.\n",
      "Alignment: [(0, 0), (1, 1), (2, 2), (2, 4), (3, 3), (4, 4), (6, 2), (6, 5), (7, 6), (8, 5), (9, 7), (11, 9), (12, 8), (13, 10), (14, 2), (14, 4), (14, 11), (14, 12), (16, 9), (17, 13), (18, 14), (19, 15)]\n",
      "\n",
      "#Пара 5:\n",
      "RU: С самого утра меня стала мучить какая-то удивительная тоска.\n",
      "EN: From\n",
      "early morning I had been oppressed by a strange despondency.\n",
      "Alignment: [(0, 0), (1, 1), (2, 2), (2, 10), (3, 3), (4, 9), (5, 6), (6, 4), (6, 5), (6, 8), (7, 7), (7, 10), (8, 10)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import chardet\n",
    "from razdel import sentenize\n",
    "from simalign import SentenceAligner\n",
    "\n",
    "RU_FILE = \"belye_nochi_ru.txt\"\n",
    "EN_FILE = \"belye_nochi_en.txt\"\n",
    "\n",
    "def detect_encoding(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return chardet.detect(f.read())[\"encoding\"]\n",
    "\n",
    "def read_text(path):\n",
    "    enc = detect_encoding(path)\n",
    "    with open(path, \"r\", encoding=enc, errors=\"ignore\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def tokenize_ru(text):\n",
    "    return [s.text for s in sentenize(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    sents = re.split(r'(?<=[\\.!?])\\s+', text.strip())\n",
    "    return [s for s in sents if s]\n",
    "\n",
    "def run_simalign(rus_sents, eng_sents, model_name=\"distilbert-base-multilingual-cased\", output_file=None):\n",
    "    print(\"Инициализация SimAlign...\")\n",
    "\n",
    "    # Подбираем корректный слой для distilbert, у неё всего 7 слоев (0..6)\n",
    "    layer_for_model = None\n",
    "    if model_name.startswith(\"distilbert\"):\n",
    "        layer_for_model = 6  # последний слой\n",
    "\n",
    "    try:\n",
    "        if layer_for_model is not None:\n",
    "            aligner = SentenceAligner(model=model_name,\n",
    "                                      token_type=\"bpe\",\n",
    "                                      matching_methods=\"mwmf\",\n",
    "                                      layer=layer_for_model)\n",
    "        else:\n",
    "            aligner = SentenceAligner(model=model_name,\n",
    "                                      token_type=\"bpe\",\n",
    "                                      matching_methods=\"mwmf\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при создании aligner с методом 'mwmf': {e}\")\n",
    "        print(\"Попытка инициализации без параметра matching_methods...\")\n",
    "        try:\n",
    "            if layer_for_model is not None:\n",
    "                aligner = SentenceAligner(model=model_name,\n",
    "                                          token_type=\"bpe\",\n",
    "                                          layer=layer_for_model)\n",
    "            else:\n",
    "                aligner = SentenceAligner(model=model_name,\n",
    "                                          token_type=\"bpe\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Ошибка при создании aligner без matching_methods: {e2}\")\n",
    "            raise e2\n",
    "\n",
    "    print(\"SimAlign инициализирован успешно!\")\n",
    "\n",
    "    flags = []\n",
    "    results = []\n",
    "\n",
    "    print(f\"Начинаем обработку {len(rus_sents[:10])} предложений...\")\n",
    "\n",
    "    for i, (r, e) in enumerate(zip(rus_sents[:10], eng_sents[:10])):\n",
    "        print(f\"Обработка пары {i+1}...\")\n",
    "        r_tokens = r.split()\n",
    "        e_tokens = e.split()\n",
    "\n",
    "        try:\n",
    "            res = aligner.get_word_aligns(r_tokens, e_tokens)\n",
    "            print(f\"Ключи в результате: {list(res.keys())}\")\n",
    "            if not res:\n",
    "                print(\"Пустой результат выравнивания\")\n",
    "                aligned_pairs = []\n",
    "            else:\n",
    "                method_name = list(res.keys())[0]\n",
    "                print(f\"Используем метод: {method_name}\")\n",
    "                aligned_pairs = res.get(method_name, [])\n",
    "\n",
    "            has_align = bool(aligned_pairs)\n",
    "            flags.append(has_align)\n",
    "            results.append({\"ru_tokens\": r_tokens,\n",
    "                            \"en_tokens\": e_tokens,\n",
    "                            \"alignment\": aligned_pairs})\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при выравнивании пары {i+1}: {e}\")\n",
    "            flags.append(False)\n",
    "            results.append({\"ru_tokens\": r_tokens,\n",
    "                            \"en_tokens\": e_tokens,\n",
    "                            \"alignment\": []})\n",
    "\n",
    "    return flags, results\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Чтение файлов...\")\n",
    "    ru_text = read_text(RU_FILE)\n",
    "    en_text = read_text(EN_FILE)\n",
    "\n",
    "    print(\"Токенизация...\")\n",
    "    rus_sents = tokenize_ru(ru_text)\n",
    "    eng_sents = tokenize_en(en_text)\n",
    "\n",
    "    n = min(len(rus_sents), len(eng_sents))\n",
    "    rus_sents = rus_sents[:n]\n",
    "    eng_sents = eng_sents[:n]\n",
    "\n",
    "    print(f\"Обработано предложений: {n}\")\n",
    "\n",
    "    try:\n",
    "        import simalign\n",
    "        version = getattr(simalign, '__version__', 'Неизвестно')\n",
    "        print(f\"Версия SimAlign: {version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при проверке версии: {e}\")\n",
    "\n",
    "    print(\"Проверка методов SimAlign...\")\n",
    "    try:\n",
    "        test_aligner = SentenceAligner(model=\"bert-base-multilingual-cased\")\n",
    "\n",
    "        import inspect\n",
    "        try:\n",
    "            sig = inspect.signature(SentenceAligner.__init__)\n",
    "            if 'matching_methods' in sig.parameters:\n",
    "                param = sig.parameters['matching_methods']\n",
    "                print(f\"Параметр matching_methods: {param.default}\")\n",
    "            else:\n",
    "                print(\"matching_methods не найден в сигнатуре\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при проверке сигнатуры: {e}\")\n",
    "\n",
    "        print(\"Тестовый запуск...\")\n",
    "        ru_sample = \"Это тестовое предложение\"\n",
    "        en_sample = \"This is a test sentence\"\n",
    "        result = test_aligner.get_word_aligns(ru_sample.split(), en_sample.split())\n",
    "        print(f\"Доступные методы в результате: {list(result.keys())}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при проверке методов: {e}\")\n",
    "\n",
    "    print(\"Запуск основного выравнивания...\")\n",
    "    try:\n",
    "        flags, aligned = run_simalign(rus_sents, eng_sents)\n",
    "        total_aligned = sum(flags)\n",
    "        print(f\"SimAlign нашёл выравнивание в {total_aligned}/{n} предложениях\\n\")\n",
    "\n",
    "        print(\"Примеры выравниваний (первые 5):\\n\")\n",
    "        count = 0\n",
    "        for i, item in enumerate(aligned):\n",
    "            if flags[i]:\n",
    "                print(f\"#Пара {i+1}:\")\n",
    "                print(\"RU:\", rus_sents[i])\n",
    "                print(\"EN:\", eng_sents[i])\n",
    "                print(\"Alignment:\", item['alignment'])\n",
    "                print()\n",
    "                count += 1\n",
    "                if count >= 5:\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"Error running SimAlign: {e}\")\n",
    "        try:\n",
    "            import simalign\n",
    "            print(f\"SimAlign version: {simalign.__version__ if hasattr(simalign, '__version__') else 'Unknown'}\")\n",
    "        except:\n",
    "            print(\"Couldn't determine SimAlign version\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3314f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чтение файлов...\n",
      "Токенизация...\n",
      "Всего предложений: 1064\n",
      "Запуск выравнивания...\n",
      "Инициализация SimAlign...\n",
      "Ошибка при создании aligner: 'inter'\n",
      "Попытка создания с настройками по умолчанию...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 02:10:01,906 - simalign.simalign - INFO - Initialized the EmbeddingLoader with model: distilbert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimAlign готов!\n",
      "Обработка 1064 предложений...\n",
      "Обработано 0/1064 предложений...\n",
      "Обработано 50/1064 предложений...\n",
      "Обработано 100/1064 предложений...\n",
      "Обработано 150/1064 предложений...\n",
      "Обработано 200/1064 предложений...\n",
      "Обработано 250/1064 предложений...\n",
      "Обработано 300/1064 предложений...\n",
      "Обработано 350/1064 предложений...\n",
      "Обработано 400/1064 предложений...\n",
      "Обработано 450/1064 предложений...\n",
      "Обработано 500/1064 предложений...\n",
      "Обработано 550/1064 предложений...\n",
      "Обработано 600/1064 предложений...\n",
      "Обработано 650/1064 предложений...\n",
      "Обработано 700/1064 предложений...\n",
      "Обработано 750/1064 предложений...\n",
      "Обработано 800/1064 предложений...\n",
      "Обработано 850/1064 предложений...\n",
      "Обработано 900/1064 предложений...\n",
      "Обработано 950/1064 предложений...\n",
      "Обработано 1000/1064 предложений...\n",
      "Обработано 1050/1064 предложений...\n",
      "Результаты сохранены в файл alignment_results.txt\n",
      "\n",
      "Метод inter:\n",
      "Выравниваний: 1064/1064\n",
      "Средняя косинусная схожесть: 0.5904\n",
      "\n",
      "Примеры для inter (первые 5):\n",
      "#Пара 1:\n",
      "RU: Ночь первая\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Была чудная ночь, такая ночь, которая разве только и может быть тогда, когда мы молоды, любезный читатель.\n",
      "EN: FIRST NIGHT\n",
      "\n",
      "It was a wonderful night, such a night as is only possible when we are\n",
      "young, dear reader.\n",
      "Выравнивание: [(3, 5), (4, 6), (5, 7), (11, 13), (14, 14), (15, 15), (16, 17), (18, 19)]\n",
      "Косинусная схожесть: 0.6896\n",
      "\n",
      "#Пара 2:\n",
      "RU: Небо было такое звездное, такое светлое небо, что, взглянув на него, невольно нужно было спросить себя: неужели же могут жить под таким небом разные сердитые и капризные люди?\n",
      "EN: The sky was so starry, so bright that, looking at\n",
      "it, one could not help asking oneself whether ill-humoured and\n",
      "capricious people could live under such a sky.\n",
      "Выравнивание: [(1, 2), (3, 4), (5, 4), (6, 1), (7, 7), (9, 9), (10, 10), (18, 22), (19, 23), (20, 24), (21, 25), (22, 27), (25, 19), (26, 18), (26, 20), (27, 21), (27, 27)]\n",
      "Косинусная схожесть: 0.6751\n",
      "\n",
      "#Пара 3:\n",
      "RU: Это тоже молодой вопрос, любезный читатель, очень молодой, но пошли его вам господь чаще на душу!..\n",
      "EN: That is a youthful\n",
      "question too, dear reader, very youthful, but may the Lord put it more\n",
      "frequently into your heart!...\n",
      "Выравнивание: [(0, 0), (1, 1), (3, 4), (5, 7), (6, 8), (7, 9), (8, 10), (10, 15), (11, 6), (15, 20)]\n",
      "Косинусная схожесть: 0.6897\n",
      "\n",
      "#Пара 4:\n",
      "RU: Говоря о капризных и разных сердитых господах, я не мог не припомнить и своего благонравного поведения во весь этот день.\n",
      "EN: Speaking of capricious and ill-humoured\n",
      "people, I cannot help recalling my moral condition all that day.\n",
      "Выравнивание: [(1, 1), (2, 2), (2, 4), (3, 3), (6, 5), (7, 6), (9, 7), (13, 10), (17, 13), (18, 14), (19, 15)]\n",
      "Косинусная схожесть: 0.6317\n",
      "\n",
      "#Пара 5:\n",
      "RU: С самого утра меня стала мучить какая-то удивительная тоска.\n",
      "EN: From\n",
      "early morning I had been oppressed by a strange despondency.\n",
      "Выравнивание: [(0, 0), (1, 1), (3, 3), (7, 10), (8, 10)]\n",
      "Косинусная схожесть: 0.5205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import chardet\n",
    "from razdel import sentenize\n",
    "from simalign import SentenceAligner\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "RU_FILE = \"belye_nochi_ru.txt\"\n",
    "EN_FILE = \"belye_nochi_en.txt\"\n",
    "OUTPUT_FILE = \"alignment_results.txt\"\n",
    "\n",
    "def detect_encoding(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return chardet.detect(f.read())[\"encoding\"]\n",
    "\n",
    "def read_text(path):\n",
    "    enc = detect_encoding(path)\n",
    "    with open(path, \"r\", encoding=enc, errors=\"ignore\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def tokenize_ru(text):\n",
    "    return [s.text for s in sentenize(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    sents = re.split(r'(?<=[\\.!?])\\s+', text.strip())\n",
    "    return [s for s in sents if s]\n",
    "\n",
    "def get_embeddings(tokens, model, tokenizer, device='cpu'):\n",
    "    inputs = tokenizer(tokens, return_tensors=\"pt\", padding=True, truncation=True, is_split_into_words=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "def run_simalign(rus_sents, eng_sents, model_name=\"distilbert-base-multilingual-cased\", output_file=None):\n",
    "    print(\"Инициализация SimAlign...\")\n",
    "    methods = [\"inter\", \"itermax\"]\n",
    "    try:\n",
    "        aligner = SentenceAligner(model=model_name, token_type=\"bpe\", matching_methods=methods)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при создании aligner: {e}\")\n",
    "        print(\"Попытка создания с настройками по умолчанию...\")\n",
    "        aligner = SentenceAligner(model=model_name, token_type=\"bpe\", layer=5)\n",
    "        methods = [\"inter\"]\n",
    "\n",
    "    print(\"SimAlign готов!\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    flags = {method: [] for method in methods}\n",
    "    results = {method: [] for method in methods}\n",
    "    cosine_scores = {method: [] for method in methods}\n",
    "\n",
    "    print(f\"Обработка {len(rus_sents)} предложений...\")\n",
    "\n",
    "    if output_file:\n",
    "        f_out = open(output_file, 'w', encoding='utf-8')\n",
    "        f_out.write(f\"Всего предложений для обработки: {len(rus_sents)}\\n\\n\")\n",
    "\n",
    "    for i, (r, e) in enumerate(zip(rus_sents, eng_sents)):\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Обработано {i}/{len(rus_sents)} предложений...\")\n",
    "\n",
    "        r_tokens = r.split()\n",
    "        e_tokens = e.split()\n",
    "\n",
    "        try:\n",
    "            res = aligner.get_word_aligns(r_tokens, e_tokens)\n",
    "            for method in methods:\n",
    "                if method not in res:\n",
    "                    print(f\"Предупреждение: метод '{method}' отсутствует в результатах.\")\n",
    "                    flags[method].append(False)\n",
    "                    results[method].append({\"ru_tokens\": r_tokens, \"en_tokens\": e_tokens, \"alignment\": []})\n",
    "                    cosine_scores[method].append(0.0)\n",
    "                    continue\n",
    "\n",
    "                aligned_pairs = res[method]\n",
    "                has_align = bool(aligned_pairs)\n",
    "                flags[method].append(has_align)\n",
    "                results[method].append({\"ru_tokens\": r_tokens, \"en_tokens\": e_tokens, \"alignment\": aligned_pairs})\n",
    "\n",
    "                if has_align:\n",
    "                    ru_aligned = [r_tokens[idx] for idx, _ in aligned_pairs if idx < len(r_tokens)]\n",
    "                    en_aligned = [e_tokens[idx] for _, idx in aligned_pairs if idx < len(e_tokens)]\n",
    "                    if ru_aligned and en_aligned:\n",
    "                        ru_embeds = get_embeddings(ru_aligned, model, tokenizer, device)\n",
    "                        en_embeds = get_embeddings(en_aligned, model, tokenizer, device)\n",
    "                        cos_sim = cosine_similarity(ru_embeds, en_embeds).diagonal().mean()\n",
    "                        cosine_scores[method].append(cos_sim)\n",
    "                    else:\n",
    "                        cosine_scores[method].append(0.0)\n",
    "                else:\n",
    "                    cosine_scores[method].append(0.0)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка в паре {i+1}: {e}\")\n",
    "            for method in methods:\n",
    "                flags[method].append(False)\n",
    "                results[method].append({\"ru_tokens\": r_tokens, \"en_tokens\": e_tokens, \"alignment\": []})\n",
    "                cosine_scores[method].append(0.0)\n",
    "\n",
    "    if output_file:\n",
    "        for method in methods:\n",
    "            total_aligned = sum(flags[method])\n",
    "            avg_cosine = np.mean([score for score in cosine_scores[method] if score > 0]) if any(score > 0 for score in cosine_scores[method]) else 0.0\n",
    "\n",
    "            f_out.write(f\"\\nМетод {method}:\\n\")\n",
    "            f_out.write(f\"Выравниваний: {total_aligned}/{len(rus_sents)}\\n\")\n",
    "            f_out.write(f\"Средняя косинусная схожесть: {avg_cosine:.4f}\\n\\n\")\n",
    "\n",
    "            f_out.write(f\"Примеры для {method} (первые 20):\\n\")\n",
    "            count = 0\n",
    "            for i, item in enumerate(results[method]):\n",
    "                if flags[method][i]:\n",
    "                    f_out.write(f\"#Пара {i+1}:\\n\")\n",
    "                    f_out.write(f\"RU: {rus_sents[i]}\\n\")\n",
    "                    f_out.write(f\"EN: {eng_sents[i]}\\n\")\n",
    "                    f_out.write(f\"Выравнивание: {item['alignment']}\\n\")\n",
    "                    f_out.write(f\"Косинусная схожесть: {cosine_scores[method][i]:.4f}\\n\\n\")\n",
    "                    count += 1\n",
    "                    if count >= 20:\n",
    "                        break\n",
    "\n",
    "        f_out.close()\n",
    "        print(f\"Результаты сохранены в файл {output_file}\")\n",
    "\n",
    "    return flags, results, cosine_scores\n",
    "\n",
    "def main():\n",
    "    print(\"Чтение файлов...\")\n",
    "    ru_text = read_text(RU_FILE)\n",
    "    en_text = read_text(EN_FILE)\n",
    "\n",
    "    print(\"Токенизация...\")\n",
    "    rus_sents = tokenize_ru(ru_text)\n",
    "    eng_sents = tokenize_en(en_text)\n",
    "\n",
    "    rus_sents = [s for s in rus_sents if s.strip()]\n",
    "    eng_sents = [s for s in eng_sents if s.strip()]\n",
    "    n = min(len(rus_sents), len(eng_sents))\n",
    "    rus_sents = rus_sents[:n]\n",
    "    eng_sents = eng_sents[:n]\n",
    "\n",
    "    print(f\"Всего предложений: {n}\")\n",
    "\n",
    "    print(\"Запуск выравнивания...\")\n",
    "    try:\n",
    "        flags, aligned, cosine_scores = run_simalign(rus_sents, eng_sents, output_file=OUTPUT_FILE)\n",
    "        \n",
    "        for method in flags.keys():\n",
    "            total_aligned = sum(flags[method])\n",
    "            avg_cosine = np.mean([score for score in cosine_scores[method] if score > 0]) if any(score > 0 for score in cosine_scores[method]) else 0.0\n",
    "            \n",
    "            print(f\"\\nМетод {method}:\")\n",
    "            print(f\"Выравниваний: {total_aligned}/{n}\")\n",
    "            print(f\"Средняя косинусная схожесть: {avg_cosine:.4f}\")\n",
    "            \n",
    "            print(f\"\\nПримеры для {method} (первые 5):\")\n",
    "            count = 0\n",
    "            for i, item in enumerate(aligned[method]):\n",
    "                if flags[method][i]:\n",
    "                    print(f\"#Пара {i+1}:\")\n",
    "                    print(\"RU:\", rus_sents[i])\n",
    "                    print(\"EN:\", eng_sents[i])\n",
    "                    print(\"Выравнивание:\", item['alignment'])\n",
    "                    print(f\"Косинусная схожесть: {cosine_scores[method][i]:.4f}\\n\")\n",
    "                    count += 1\n",
    "                    if count >= 5:\n",
    "                        break\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка SimAlign: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
